# 模型评估与选择
## 经验误差和过拟合
误差：训练集上：训练误差/经验误差
新样本：泛化误差

**过拟合**: 只要相信`P!=NP`，就无法解决，只能缓解
> NP (Nondeterministic Polynomial)问题指的是能够在多项式的时间里验证一个解是否正确的问题。
> P问题指的是能够在多项式的时间里得到解决的问题，非对称加密算法其安全性正是建立在NP问题无法被转换成P问题的基础上。
> 证明 P=NP 的一个主要方法就是，给某一个 NPC 问题找到一个快速算法

机器学习面对的问题通常是`NP-hard` 甚至更难，而有效的学习算法必然是在多项式时间内运行完成
欠拟合：在决策树中扩展分支，在神经网络中增加轮数。

## 评估方法
测试集，测试误差作为泛化误差的近似
产生训练集和测试集
### 留出法
普通的方法
###  交叉验证法
`k-fold cross validataion `
将数据集D分成k份大小相似的护持自己，子集从D中分层采样得到。每次用k-1个子集的并集作为训练集，剩下的作为子集。随机使用不同的划分p次
如果 k = 样本数量，那么此时得到留一法`(LOO)`,留一法比较准确但是计算复杂度很高。
### 自助法 `bootstrapping`
以自助采样为基础
> **自助法**（BootstrapMethod，Bootstrapping或自助抽样法）可以指任何一种有放回的均匀抽样，也就是说，每当选中一个样本，它等可能地被再次选中并被再次添加到训练集中。自助法能对采样估计的准确性（标准误差、置信区间和偏差）进行比较好的估计，它基本上能够对任何采样分布的统计量进行估计。

通过自助采样，初始数据集D中约有`36.8%`的样本不会出现在采样数据集`D'` 中。
指实际评估模型与期望评估模型都是用mg个样本，而仍有一部分数据总量约为`1/3`的,没在训练集中出现的样本用于测试，这种情况下的测试结果称为**包外估计(out-of-bag)**

评价：
自助法适用于数据量比较小的情况。对集成等方法有好处。引入了估计误差。
在数据量充足的情况下，留出法和交叉验证法更好。

### 调参与最终模型
训练集/验证集/测试集

## 性能度量
> 定量输出称为**回归**，或者说是连续变量预测；  
定性输出称为**分类**，或者说是离散变量预测。

回归任务中常用的是均方误差
### 错误率和精度
分类任务中常用的

### 查准率（precision)、查全率(recall)与F1
二分类问题：
`true positive、false positive、true negative、false negative`。  
TP+FP+TN+FN = 样例总数
混淆矩阵    
|  真实情况   | 预测结果  |         |
| ----|-----|-----|
|  | 正例 | 反例 |
|正例| TP| FN|
|反例| FP | TN |

查准率 P 与查全率 R   
$P=\frac{TP}{TP+FP}$    
$R=\frac{TP}{TP+FN}$ 

P-R 图  
**平衡点BEP** P=R  
$F1、F_\beta$  
1. $\beta=1$ 时退化为标准 F1
2. $\beta>1$ 时查全率有更大影响
3. $\beta<1$ 时查准率有更大影响

### ROC 与 AUC 
ROC 受试者工作特征，`ROC` 图与P-R图类似  
横轴：真正例率，纵轴：假正例率。
`AUC(area under roc curve)`

### 代价敏感错误率与代价曲线
非均等代价

## 比较检验
### 假设检验
置信度、t检验
### 交叉验证t检验
若两个学习器的性能相同，则它们使用的训练/测试集得到的测试错误率应相同
在一个数据集上比较两个算法
### `McNemar` 检验
### `Friedman` 检验和 `Nemenyi` 后续检验
基于算法排序的 `Friedman` 检验

## 偏差与方差
**偏差-方差分解**是解释学习算法泛化性能的一种重要工具  
**偏差**度量了学习算法的期望预测与真是结果的偏离程度，即刻画了学习算法本身的拟合能力。  
**方差**度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响。  
**噪声**则表达了在当前任务上任何学习算法所能到达的期望泛化误差的下界，即刻画了学习问题本身的难度。  
**偏差-方差**分解说明泛化性能是由学习算法的能力，数据的充分性以及学习任务本身的难度所共同决定的。
  


**偏差-方差窘境**


## 参考资料
西瓜书
